---
title: "Hierarchical, autoregressive binomial models for MIRA 16S data"
author: "Erik Clarke"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: github_document
editor_options: 
  chunk_output_type: console
params:
  fig_fp: "figures"
  genus: "Pseudomonas"
  abx: "cefepime"
---

Click on "Code" for information on packages loaded for this analysis.
```{r setup, collapse=TRUE}
library(here)
library(tidyverse); print(packageVersion("tidyverse"))
library(phyloseq)
library(rethinking)
library(bayesplot)
library(tidybayes)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

knitr::opts_chunk$set(
  echo = TRUE,
  results="hide",
  warning=FALSE,
  message = FALSE,
  fig.width=5,
  fig.height = 3)

fig_fp <- params$fig_fp
if (!dir.exists(here(fig_fp))) {
  dir.create(here(fig_fp))
}

source(here("shared_functions.R"))

mira_theme <- theme_bw() + theme(
  strip.background = element_rect(fill = NA)
)
theme_set(mira_theme)
```

## Data

For these models, we are aggregating counts and considering only the `r params$genus` genus and `r params$abx` antibiotic.
The response variable will be the raw read counts, while the treatment will be a binary yes/no for
`r params$abx` administration on the previous day (either that or no abx), and the previous day's read counts for 
`r params$genus` (standardized).

```{r load-data, cache=TRUE}
mira <- load_mira_data(
  seqtab_fp = here("../shared/data/seqtab.rds"),
  taxa_fp = here("../shared/data/taxa.rds"),
  specimen_fp = here("../shared/data/MIRA_Specimen_Table.csv")
)
seqs <- mira$seqs
mira <- mira$ps

# Keep only the samples with abx data
mira.abx <- prune_samples(!is.na(sample_data(mira)$abx_b_number), mira)
# Converted to melted form
agg <- phyloseq_to_agglomerated(mira.abx, "specimen_id2", "otu_id", "read_count")
d <- agg %>%
  filter(specimen_type %in% c("Stool Swab", "Oral Swab", "Sputum")) %>%
  # Calculate total reads
  group_by(specimen_id2) %>%
  mutate(total_reads = sum(read_count)) %>%
  ungroup() %>%
  # Collapse reads by genus
  filter(!is.na(Genus)) %>%
  group_by(specimen_id2, total_reads, Kingdom, Phylum, Class, Order, Family, Genus) %>%
  summarise(read_count = sum(read_count)) %>%
  filter(Genus == params$genus) %>%
  left_join(sample_data(mira.abx)) %>%
  # Isolate to instances of target antibiotic
  ungroup() %>%
  separate_rows(abx_b) %>%
  filter(abx_b == params$abx | is.na(abx_b)) %>%
  # Set up lag variables, removing days with > 1 day since previous sampling
  group_by(specimen_type, subject_id) %>%
  arrange(study_day) %>%
  mutate(day_delta = study_day - lag(study_day)) %>%
  mutate(lag_count = lag(read_count)) %>%
  mutate(lag_abx_yn = ifelse(is.na(lag(abx_b)), 0, 1)) %>%
  ungroup() 
  
```

```{r shared-functions}
run_over_specimen_types <- function(d, formula, chains=2, iter=2000, ...) {
  run_model <- function(flist, data, model, ...) {
    if (missing(flist)) {
      if (missing(model)) {
        stop("Must give either a flist or model")
      }
      map2stan(
        flist=model,
        data=as.data.frame(data),
        ...
      )
    } else {
      map2stan(
        flist=flist,
        data=as.data.frame(data),
        ...
      )
    }

  } 
  
  flist=NULL
  models <- list()
  for (type in c("Stool Swab", "Oral Swab", "Sputum")) {
    d2 <- filter(d, specimen_type == type)# %>%
      # select(read_count, total_reads, specimen_id, subject_id, lag_count_s, lag_abx_yn)
    if (is.null(flist)) {
      flist <- formula
      m <- run_model(flist=flist, data=d2, chains=chains, iter=iter, ...)
      flist <- m
      print(type)
      print(precis(m))
      models[[type]] <- m
    } else {
      print("Skipping model compilation")
      m <- run_model(data=d2, model=flist, chains=chains, iter=iter, ...)
      print(type)
      print(precis(m))
      models[[type]] <- m
    }
  }
  models
}
```


## Model 1: Binomial model with specimen and subject intercepts

### Model 1.0

Random intercepts for specimen and subject.

```{r, results="hide"}

f1.0 <- alist(
  read_count ~ dbinom(total_reads, prob),
  logit(prob) <- a_0 + a_specimen[specimen_id2] + a_subject[subject_id],
  a_0 ~ dnorm(0,10),
  a_specimen[specimen_id2] ~ dnorm(0, sigma_specimen),
  a_subject[subject_id] ~ dnorm(0, sigma_subject),
  sigma_specimen ~ dcauchy(0,1),
  sigma_subject ~ dexp(1)
)

m1.0 <- d %>% 
  run_over_specimen_types(
    f1.0, iter = 4000, chains=4, cores=4, WAIC=F, control=list(adapt_delta=0.9, max_treedepth=12))
```

### Model 1.1

Single-subject, random intercepts on specimen, autoregressive on previous day.

```{r m1.1}
d1.1 <- as.list(d %>% filter(
  subject_id == "MIRA_013", specimen_type=="Sputum") %>%
  select(read_count, total_reads, specimen_id2)  %>%
  mutate(specimen_id2 = as.integer(as.factor(specimen_id2))) %>%
  mutate(emp_prob = read_count/total_reads))
d1.1$N <- length(d1.1$read_count)
d1.1$N_specimen_id2 <- n_distinct(d1.1$specimen_id2)
writeLines(readLines("arb_1.1.stan"))
m1.1 <- stan(file="arb_1.1.stan", data=d1.1, iter=5000, warmup=1000, control=list(max_treedepth=15, adapt_delta=0.9))

```

### Model 1.2

Same as 1.1, but now also with a binary predictor for `r params$abx`.

```{r m1.2}
d1.2 <- d %>% filter(
  subject_id == "MIRA_005", specimen_type=="Oral Swab") %>%
  mutate(abx_yn = !is.na(abx_b)) %>%
  select(read_count, total_reads, abx_yn, study_day, specimen_id2)  %>%
  mutate(specimen_id2 = as.factor(specimen_id2)) %>%
  mutate(study_day = study_day) %>%
  mutate(emp_prob = read_count/total_reads)

writeLines(readLines("arb_1.2.stan"))

m1.2 <- stan(
  file="arb_1.2.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))

```

```{r}
post1.2 <- spread_samples(m1.2.3, a_0, b_lag, b_abx) 
pred1.2 <- matrix(data=NA, nrow = 7500, ncol=nrow(d1.2))
emp_pred1.2 <- pred1.2
pred1.2[,1] <- d1.2$read_count[1]
emp_pred1.2[,1] <- d1.2$emp_prob[1]
for (i in 2:nrow(d1.2)) {
  pred1.2[,i] <- with(
    post1.2, 
    rbinom(7500, size=d1.2$total_reads[i], 
           prob=logistic(a_0 + b_lag*(pred1.2[,i-1]/d1.2$total_reads[i-1]) + b_abx*d1.2$abx_yn[i-1])))
  emp_pred1.2[,i] <- pred1.2[,i]/d1.2$total_reads[i]
}
colnames(emp_pred1.2) <- paste0("X", d1.2$study_day)
pred1.2.df <- gather(data.frame(emp_pred1.2))
pred1.2.df$key <- as.numeric(str_replace(pred1.2.df$key, "X", ""))
pred1.2.df <- group_by(pred1.2.df, key) %>%
  mutate(sample = seq_along(value))
pred1.2.df <- filter(pred1.2.df, sample < 100)

ggplot(pred1.2.df, aes(key, value, group=sample)) + geom_line(alpha=0.1) +
  geom_line(data=d1.2, aes(study_day, emp_prob, color="empirical", group=NULL)) +
  geom_vline(data=d1.2, aes(xintercept=study_day, alpha=abx_yn), linetype=2) +
  scale_alpha_manual(values=c("TRUE"=0.6, "FALSE"=0)) +
  scale_y_continuous(expand=c(0,0), labels=scales::percent)
```

### Model 1.2.1

Alternative parameterization of the half-Cauchy

- exp(1)

```{r}
.m <- map2stan(alist(
  read_count ~ dbinom(total_reads, prob),
  logit(prob) <- a_0 + a_specimen[specimen_id2],
  a_0 ~ dnorm(0,10),
  a_specimen[specimen_id2] ~ dnorm(0, sigma_specimen),
  sigma_specimen ~ dexp(1)
), data=data.frame(d1.2), WAIC=F)
```


```{r m1.2}

writeLines(readLines("arb_1.2.1.stan"))

m1.2.1 <- stan(
  file="arb_1.2.1.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))
m1.2.2 <- stan(
  file="arb_1.2.2.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))
# 1.2, but with transformed cauchy
m1.2.3 <- stan(
  file="arb_1.2.3.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))
```

## Model 1.3

Revisiting the intercept-only model to explore better parameterizations.

This goes right back to the start with no separate intercept `a_0`, just specimen-level intercepts.
```{r}
d1.3 <- d %>% filter(
  subject_id == "MIRA_005", specimen_type=="Oral Swab") %>%
  mutate(abx_yn = !is.na(abx_b)) %>%
  select(read_count, total_reads, abx_yn, study_day, specimen_id2)  %>%
  mutate(specimen_id2 = as.factor(specimen_id2)) %>%
  mutate(study_day = study_day) %>%
  mutate(emp_prob = read_count/total_reads)

writeLines(readLines("arb_1.2.stan"))

m1.3.0 <- stan(
  file="arb_1.3.0.stan", data=compose_data(d1.3), iter=5000, chains=3)
#  control=list(max_treedepth=15, adapt_delta=0.9))

```

### Model 1.3.1

This one changes things up a little. We use non-centered intercepts for the specimens and add back the lag parameter.

The tree depth is important here (max = 15).

```{r}

m1.3.1 <- stan(
  file="arb_1.3.1.stan", data=compose_data(d1.3), iter=5000, chains=3,
  control=list(max_treedepth=15))
```

### Model 1.3.2

Do centered vs non-centered parameterizations matter? This model uses centered parameterizations:

```{r}

m1.3.2 <- stan(
  file="arb_1.3.2.stan", data=compose_data(d1.3), iter=5000, chains=3,
  control=list(max_treedepth=15))
```

`n_eff` is generally higher in m1.3.1, indicating that non-centered parameterization does indeed lead to 
a bit more efficient sampler. 

### Model 1.3.3 

The return of antibiotic effects! And non-centered parameterization.
Notes: I had to use `vector[n] abx_yn` rather than a better `int abx_yn[n]` due to 
the vector slicing notation we're using.

```{r}
m1.3.3 <- stan(
  file="arb_1.3.3.stan", data=compose_data(d1.3), iter=5000, chains=3,
  control=list(max_treedepth=15))
```

