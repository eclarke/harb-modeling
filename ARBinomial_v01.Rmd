---
title: "Hierarchical, autoregressive binomial models for MIRA 16S data"
author: "Erik Clarke"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    code_folding: hide
editor_options: 
  chunk_output_type: console
params:
  fig_fp: "figures"
  genus: "Staphylococcus"
  species: "aureus"
  abx: "vancomyciniv"
  load_saved: FALSE
---
## Setup

Click on "Code" for information on packages loaded for this analysis.
```{r setup, collapse=TRUE}
library(here)
library(tidyverse); print(packageVersion("tidyverse"))
library(phyloseq)
library(rethinking)
library(bayesplot)
library(tidybayes)
library(ggbeeswarm)
library(magrittr)
library(tsibble)
library(knitr)
library(kableExtra)
rstan_options(auto_write = TRUE)
options(
  mc.cores = parallel::detectCores(),
  tibble.print_max = 30)

knitr::opts_chunk$set(
  echo = TRUE,
  results="hide",
  warning=FALSE,
  message = FALSE,
  fig.width=5,
  fig.height = 3,
  eval=FALSE)

fig_fp <- params$fig_fp
if (!dir.exists(here(fig_fp))) {
  dir.create(here(fig_fp))
}

source(here("shared_functions.R"))

mira_theme <- theme_bw() + theme(
  strip.background = element_rect(fill = NA)
)
theme_set(mira_theme)
```

For these models, we are aggregating counts and considering only the `r params$genus` genus and `r params$abx` antibiotic.
The response variable will be the raw read counts, while the treatment will be a binary yes/no for
`r params$abx` administration on the previous day (either that or no abx), and the previous day's read counts for 
`r params$genus` (standardized).

```{r load-data, cache=TRUE, eval=T}
mira.all <- load_mira_data(
  seqtab_fp = here("../shared/data/seqtab.rds"),
  taxa_fp = here("../shared/data/taxa.rds"),
  meds_fp = here("../shared/data/MIRA_Medications_Table.csv"),
  specimen_fp = here("../shared/data/MIRA_Specimen_Table.csv")
)

seqs <- mira.all$seqs
meds <- mira.all$meds
mira <- mira.all$ps

# Remove non-MIRA subjects from dataset (incl. blanks and controls)
.nonmira <- is.na(sample_data(mira)$subject_id)
print(sprintf("Removing %d non-MIRA samples...", sum(.nonmira)))
mira <- prune_samples(!.nonmira, mira)
# Remove culture samples (they break the subject/type/date unique constraint)
.culture <- grepl("Culture", sample_data(mira)$specimen_type)
print(sprintf("Removing %d culture samples...", sum(.culture)))
mira <- prune_samples(!.culture, mira)
# Remove empty samples
.empty <- sample_sums(mira) == 0
print(sprintf("Removing %d empty samples...", sum(.empty)))
mira <- prune_samples(!.empty, mira)

# Identify "duplicated" specimens (same subject, specimen type, and study day)
sample_data(mira) <- sample_data(mira) %>% 
  group_by(subject_id, specimen_type, study_day) %>%
  # "specimen_id3" has the same value for duplicated specimens so phyloseq can 
  # use it as a grouping level
  mutate(specimen_id3 = case_when(
    n() > 1 ~ paste0(first(as.character(specimen_id2)), "_D"),
    TRUE ~ as.character(specimen_id2)
  )) %>%
  ungroup() %>% as.data.frame() %>%
  set_rownames(.$specimen_id2)

# Sum abundances and merge sample table for duplicates
mira <- phyloseq::merge_samples(mira, "specimen_id3", fun=sum)
# Re-add the relevant metadata since merge_samples mangles factors and dates
sample_data(mira) <- sample_data(mira) %>% 
  mutate(specimen_id2 = rownames(.)) %>%
  select(specimen_id2, specimen_id3) %>%
  left_join(mira.all$samples) %>%
  ungroup() %>% as.data.frame() %>%
  set_rownames(.$specimen_id2)

# Restrict to only samples for which we have abx data
.abx_specimens <- as.character(inner_join(sample_data(mira), meds)$specimen_id2)
mira.abx <- prune_samples(
  sample_data(mira)$specimen_id2 %in% .abx_specimens, mira)

# Converted to melted form
agg <- phyloseq_to_agglomerated(mira.abx, "specimen_id2", "otu_id", "read_count")
d <- agg %>%
  # Calculate total reads
  group_by(specimen_id2) %>%
  mutate(total_reads = sum(read_count)) %>%
  ungroup() %>%
  # Collapse reads by genus/species
  filter(!is.na(Genus), !is.na(Species)) %>%
  group_by(specimen_id2, total_reads, Kingdom, Phylum, Class, Order, Family, Genus, Species) %>%
  summarise(read_count = sum(read_count)) %>%
  ungroup() %>%
  filter(Genus == params$genus) %>%
  filter(Species == params$species) %>%
  left_join(sample_data(mira.abx)) %>%
  select(-c(Kingdom:Family))

# Calculate antibiotic effectiveness windows
subjects <- sample_data(mira.abx) %>%
  group_by(subject_id) %>% 
  mutate(exit_date = max(collection_date)) %>%
  distinct(subject_id, enroll_date, exit_date) %>%
  right_join(meds) %>%
  group_by(subject_id) %>%
  mutate(study_day = as.integer(collection_date - enroll_date)) %>%
  # Limit to only a week before enrollment date and nothing after
  filter(study_day > -7, collection_date <= exit_date) %>%
  mutate(abx_yn = grepl(params$abx, abx_b)) %>%
  # the .size parameter here is how long it takes to reach peak
  # 1 = that day
  mutate(reached_peak = slide_lgl(abx_yn, all, .size=2)) %>%
  # the lag parameter here defines how long it lasts after end of admin.
  mutate(on_abx = effective_window(reached_peak, lag=0)) %>%
  ungroup()
  
# Manually split MIRA_024 into two sub-subjects
subjects <- subjects %>%
  mutate(subject_id2 = case_when(
    subject_id != "MIRA_024" ~ subject_id,
    study_day <= 33 ~ "MIRA_024a",
    study_day >= 73 ~ "MIRA_024b",
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(subject_id2))

d2 <- left_join(subjects, d)
```

```{r, eval=T, fig.width=10, fig.height=10}
subjects %>% 
  gather(key=key, value=value, abx_yn, reached_peak, on_abx) %>%
  ggplot(aes(study_day, key)) +
  geom_tile(aes(fill=value), color="white", size=0.5) +
  geom_vline(aes(xintercept=0)) +
  facet_wrap(vars(subject_id), ncol=2, scales="free_x") +
  scale_x_continuous(expand=c(0,0)) +
  scale_fill_manual(values=c("TRUE"="dodgerblue", "FALSE"="lightgrey"))
```

```{r eval=T, fig.width=10, fig.height=10}
d2 %>% 
  filter(specimen_type == "Sputum" | is.na(specimen_type)) %>%
  group_by(subject_id2) %>%
  mutate(prop = read_count/total_reads) %>%
#  mutate(delta = prop-lag(prop)) %>%
  ggplot(aes(study_day, color=on_abx, group=subject_id2)) +
  geom_line(aes(y=prop)) +
  geom_point(aes(y=prop)) +
  geom_point(aes(y=0), shape=0) +
  facet_wrap(vars(subject_id2), ncol=3, scales="free")
  
```


## Model 1: Binomial model with specimen and subject intercepts

### Model 1.0

Random intercepts for specimen and subject.

```{r, results="hide"}
run_over_specimen_types <- function(d, formula, chains=2, iter=2000, ...) {
  run_model <- function(flist, data, model, ...) {
    if (missing(flist)) {
      if (missing(model)) {
        stop("Must give either a flist or model")
      }
      map2stan(
        flist=model,
        data=as.data.frame(data),
        ...
      )
    } else {
      map2stan(
        flist=flist,
        data=as.data.frame(data),
        ...
      )
    }

  } 
  
  flist=NULL
  models <- list()
  for (type in c("Stool Swab", "Oral Swab", "Sputum")) {
    d2 <- filter(d, specimen_type == type)# %>%
      # select(read_count, total_reads, specimen_id, subject_id, lag_count_s, lag_abx_yn)
    if (is.null(flist)) {
      flist <- formula
      m <- run_model(flist=flist, data=d2, chains=chains, iter=iter, ...)
      flist <- m
      print(type)
      print(precis(m))
      models[[type]] <- m
    } else {
      print("Skipping model compilation")
      m <- run_model(data=d2, model=flist, chains=chains, iter=iter, ...)
      print(type)
      print(precis(m))
      models[[type]] <- m
    }
  }
  models
}
f1.0 <- alist(
  read_count ~ dbinom(total_reads, prob),
  logit(prob) <- a_0 + a_specimen[specimen_id2] + a_subject[subject_id],
  a_0 ~ dnorm(0,10),
  a_specimen[specimen_id2] ~ dnorm(0, sigma_specimen),
  a_subject[subject_id] ~ dnorm(0, sigma_subject),
  sigma_specimen ~ dcauchy(0,1),
  sigma_subject ~ dexp(1)
)

m1.0 <- d %>% 
  run_over_specimen_types(
    f1.0, iter = 4000, chains=4, cores=4, WAIC=F, control=list(adapt_delta=0.9, max_treedepth=12))
```

### Model 1.1

Single-subject, random intercepts on specimen, autoregressive on previous day.

```{r m1.1}
d1.1 <- as.list(d %>% filter(
  subject_id == "MIRA_013", specimen_type=="Sputum") %>%
  select(read_count, total_reads, specimen_id2)  %>%
  mutate(specimen_id2 = as.integer(as.factor(specimen_id2))) %>%
  mutate(emp_prob = read_count/total_reads))
d1.1$N <- length(d1.1$read_count)
d1.1$N_specimen_id2 <- n_distinct(d1.1$specimen_id2)
writeLines(readLines("arb_1.1.stan"))
m1.1 <- stan(file="arb_1.1.stan", data=d1.1, iter=5000, warmup=1000, control=list(max_treedepth=15, adapt_delta=0.9))

```

### Model 1.2

Same as 1.1, but now also with a binary predictor for `r params$abx`.

```{r}
d1.2 <- d %>% filter(
  subject_id == "MIRA_005", specimen_type=="Oral Swab") %>%
  mutate(abx_yn = !is.na(abx_b)) %>%
  select(read_count, total_reads, abx_yn, study_day, specimen_id2)  %>%
  mutate(specimen_id2 = as.factor(specimen_id2)) %>%
  mutate(study_day = study_day) %>%
  mutate(emp_prob = read_count/total_reads)

writeLines(readLines("arb_1.2.stan"))

m1.2 <- stan(
  file="arb_1.2.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))

```

```{r}
post1.2 <- spread_samples(m1.2.3, a_0, b_lag, b_abx) 
pred1.2 <- matrix(data=NA, nrow = 7500, ncol=nrow(d1.2))
emp_pred1.2 <- pred1.2
pred1.2[,1] <- d1.2$read_count[1]
emp_pred1.2[,1] <- d1.2$emp_prob[1]
for (i in 2:nrow(d1.2)) {
  pred1.2[,i] <- with(
    post1.2, 
    rbinom(7500, size=d1.2$total_reads[i], 
           prob=logistic(a_0 + b_lag*(pred1.2[,i-1]/d1.2$total_reads[i-1]) + b_abx*d1.2$abx_yn[i-1])))
  emp_pred1.2[,i] <- pred1.2[,i]/d1.2$total_reads[i]
}
colnames(emp_pred1.2) <- paste0("X", d1.2$study_day)
pred1.2.df <- gather(data.frame(emp_pred1.2))
pred1.2.df$key <- as.numeric(str_replace(pred1.2.df$key, "X", ""))
pred1.2.df <- group_by(pred1.2.df, key) %>%
  mutate(sample = seq_along(value))
pred1.2.df <- filter(pred1.2.df, sample < 100)

ggplot(pred1.2.df, aes(key, value, group=sample)) + geom_line(alpha=0.1) +
  geom_line(data=d1.2, aes(study_day, emp_prob, color="empirical", group=NULL)) +
  geom_vline(data=d1.2, aes(xintercept=study_day, alpha=abx_yn), linetype=2) +
  scale_alpha_manual(values=c("TRUE"=0.6, "FALSE"=0)) +
  scale_y_continuous(expand=c(0,0), labels=scales::percent)
```

### Model 1.2.1

Alternative parameterization of the half-Cauchy

- exp(1)

```{r}
.m <- map2stan(alist(
  read_count ~ dbinom(total_reads, prob),
  logit(prob) <- a_0 + a_specimen[specimen_id2],
  a_0 ~ dnorm(0,10),
  a_specimen[specimen_id2] ~ dnorm(0, sigma_specimen),
  sigma_specimen ~ dexp(1)
), data=data.frame(d1.2), WAIC=F)
```


```{r}

writeLines(readLines("arb_1.2.1.stan"))

m1.2.1 <- stan(
  file="arb_1.2.1.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))
m1.2.2 <- stan(
  file="arb_1.2.2.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))
# 1.2, but with transformed cauchy
m1.2.3 <- stan(
  file="arb_1.2.3.stan", data=compose_data(d1.2), iter=5000, chains=3,
  control=list(max_treedepth=15, adapt_delta=0.99))
```

## Model 1.3

Revisiting the intercept-only model to explore better parameterizations.

This goes right back to the start with no separate intercept `a_0`, just specimen-level intercepts.
```{r}
d1.3 <- d %>% filter(
  subject_id == "MIRA_005", specimen_type=="Oral Swab") %>%
  mutate(abx_yn = !is.na(abx_b)) %>%
  select(read_count, total_reads, abx_yn, study_day, specimen_id2)  %>%
  mutate(specimen_id2 = as.factor(specimen_id2)) %>%
  mutate(study_day = study_day) %>%
  mutate(emp_prob = read_count/total_reads)

writeLines(readLines("arb_1.2.stan"))

m1.3.0 <- stan(
  file="arb_1.3.0.stan", data=compose_data(d1.3), iter=5000, chains=3)
#  control=list(max_treedepth=15, adapt_delta=0.9))

```

### Model 1.3.1

This one changes things up a little. We use non-centered intercepts for the specimens and add back the lag parameter.

The tree depth is important here (max = 15).

```{r}

m1.3.1 <- stan(
  file="arb_1.3.1.stan", data=compose_data(d1.3), iter=5000, chains=3,
  control=list(max_treedepth=15))
```

### Model 1.3.2

Do centered vs non-centered parameterizations matter? This model uses centered parameterizations:

```{r}

m1.3.2 <- stan(
  file="arb_1.3.2.stan", data=compose_data(d1.3), iter=5000, chains=3,
  control=list(max_treedepth=15))
```

`n_eff` is generally higher in m1.3.1, indicating that non-centered parameterization does indeed lead to 
a bit more efficient sampler. 

### Model 1.3.3 

The return of antibiotic effects! And non-centered parameterization.
Notes: I had to use `vector[n] abx_yn` rather than a better `int abx_yn[n]` due to 
the vector slicing notation we're using.

```{r}
m1.3.3 <- stan(
  file="arb_1.3.3.stan", data=compose_data(d1.3), iter=5000, chains=3,
  control=list(max_treedepth=15))
```

I've added a 'generated quantities' block that converts back from alpha_std to alpha, 
and these values recapitulate what I got from m1.3.2 (the centered version).

Okay. So this is the "gold standard" for now. 

## Model 1.4

In this model I want to explore subject-level random effects. It should be as easy as 
adding a second non-centered reparameterization around a second alpha, right?

For sanity's sake, I'm removing the lag and antibiotic terms for now.

```{r}
d1.4 <- d %>% filter(
  subject_id %in% c("MIRA_005", "MIRA_004", "MIRA_007"), specimen_type=="Oral Swab") %>%
  mutate(abx_yn = !is.na(abx_b)) %>%
  select(read_count, total_reads, abx_yn, study_day, subject_id, specimen_id2)  %>%
  mutate(specimen_id2 = as.factor(specimen_id2)) %>%
  mutate(subject_id = as.factor(droplevels(subject_id))) %>%
  mutate(study_day = study_day) %>%
  mutate(emp_prob = read_count/total_reads)

m1.4.0 <- stan(
  file="arb_1.4.0.stan", data=compose_data(d1.4), iter=2000, chains=4,
  control=list(max_treedepth=15, adapt_delta=0.9))

bayesplot::mcmc_trace(extract(m1.4.0, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]"))
pairs(m1.4.0, pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]"))
```

Couple of things to note: 

- Though I expected it to be a 1-to-1 relationship, putting the transformed random intercepts in the 
transformed parameters block led to serious divergences. I'm keeping them outside that block now, in the model block.
- I've used exponential priors for the sigma terms here but I'm not sure they're necessary. 
- This samples relatively efficiently.

```{r}
invisible(with(data.frame(), {
  browser()
  post <- tidybayes::spread_samples(model=m1.4.0, a_subj[subject_id], sigma_subj) %>%
    group_by(subject_id)
  .d <- d1.4 %>% mutate(subject_id = as.integer(subject_id))
  ggplot(post, aes(subject_id, logistic(a_subj), group=subject_id)) + geom_quasirandom(shape=21) +
    geom_quasirandom(data=.d, aes(y=emp_prob))
}))

```

This shows the subject-level intercepts reasonably reconstituting the empirical data. They're all
pulled towards zero, which I expect is closer to the median thanks to the one subject of the three
that's mostly zero.

### Model 1.4.1

Let's explore now how to add a lag term to this model. First I'll start by rewriting it
to be "ragged"; i.e. each subject's terms are fit separately. 

```{r}
d1.4.1 <- d1.4 %>% arrange(subject_id, study_day) %>% compose_data()
d1.4.1$n_obs_subject <- (d1.4 %>% group_by(subject_id) %>% summarize(n = n()))$n

m1.4.1 <- stan(
  file="arb_1.4.1.stan", data=d1.4.1, iter=2000, chains=4,
  control=list(max_treedepth=15, adapt_delta=0.9))
```

This model works about as well as 1.4.0. The estimates are very similar.

### Model 1.4.2

Now that we have a for-loop over each subject, we should be able to add the 
correct lag term.

```{r}
m1.4.2 <- stan(
  file="arb_1.4.2.stan", data=d1.4.1, iter=2000, chains=4,
  control=list(max_treedepth=15, adapt_delta=0.9))

bayesplot::mcmc_trace(extract(m1.4.2, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag"))
pairs(m1.4.2, pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag"))
```

This model converges fine and seems reasonable. I'm not simulating from the posterior yet.

### Model 1.4.3

Let's add a subject-level effect for antibiotics without pooling (for now).
My intuition for this will be that it fits slower, and has a hard time converging.
I may have been better off estimating b_abx with complete pooling.

```{r}
m1.4.3 <- stan(
  file="arb_1.4.3.stan", data=d1.4.1, iter=2000, chains=4,
  control=list(max_treedepth=17, adapt_delta=0.95))

bayesplot::mcmc_trace(extract(m1.4.3, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag", "b_abx[1]"))
pairs(m1.4.3, pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag", "b_abx[1]"))
```

This converges with 3 divergent iterations and no treedepth warnings.

### Model 1.4.4

Partial pooling on b_abx.

```{r}
m1.4.4 <- stan(
  file="arb_1.4.4.stan", data=d1.4.1, iter=2000, chains=4,
  control=list(max_treedepth=17, adapt_delta=0.95))

bayesplot::mcmc_trace(extract(m1.4.4, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag", "b_abx[1]"))
pairs(m1.4.4, pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag", "b_abx[1]"))
```

This fits okay on the restricted 3-subject dataset, so let's try it on the full dataset:

```{r}
d1.4.4.os <- d %>% filter(specimen_type=="Oral Swab") %>%
  group_by(subject_id) %>%
  filter(n() > 1) %>%
  ungroup() %>%
  mutate(abx_yn = !is.na(abx_b)) %>%
  select(read_count, total_reads, abx_yn, study_day, subject_id, specimen_id2)  %>%
  mutate(specimen_id2 = as.factor(specimen_id2)) %>%
  mutate(subject_id = as.factor(droplevels(subject_id))) %>%
  mutate(study_day = study_day) %>%
  mutate(emp_prob = read_count/total_reads)
d1.4.4.osl <- d1.4.4.os %>% arrange(subject_id, study_day) %>% compose_data()
d1.4.4.osl$n_obs_subject <- (d1.4.4.os %>% group_by(subject_id) %>% summarize(n = n()))$n

m1.4.4a <- stan(
  file="arb_1.4.4.stan", data=d1.4.4.osl, iter=2000, chains=4,
  control=list(max_treedepth=17, adapt_delta=0.95))
saveRDS(m1.4.4a, file = "fit_arb_1.4.4_oralswab.rds")
```

It fits! Took about an hour or more to do so.

#### Fitting on other sample types

```{r}
d1.4.4.sp <- d %>% filter(specimen_type=="Sputum") %>%
  group_by(subject_id) %>%
  filter(n() > 1) %>%
  ungroup() %>%
  mutate(abx_yn = !is.na(abx_b)) %>%
  select(read_count, total_reads, abx_yn, study_day, subject_id, specimen_id2)  %>%
  mutate(specimen_id2 = as.factor(specimen_id2)) %>%
  mutate(subject_id = as.factor(droplevels(subject_id))) %>%
  mutate(study_day = study_day) %>%
  mutate(emp_prob = read_count/total_reads) %>%
  ungroup() %>%
  arrange(subject_id, study_day)
d1.4.4.spl <- compose_data(d1.4.4.sp)
d1.4.4.spl$n_obs_subject <- (d1.4.4.sp %>% group_by(subject_id) %>% summarize(n = n()))$n

m1.4.4.sp <- stan(
  file="arb_1.4.4.stan", data=d1.4.4.spl, iter=2000, chains=4,
  control=list(max_treedepth=17, adapt_delta=0.95))
saveRDS(m1.4.4.sp, file = "fit_arb_1.4.4_sputum.rds")
```


## Model 1.5

After all the difficulties around 1.4 and vector slicing, I realized that simply by specifying the lagged values
in the data, we'd recapitulate what we're doing with the slicing operations. Stan is not learning from the 
previous day's fit, it's learning from the previous day's data just as if we added a lagged value. 

Plus, we would like to add lead and lag times to antibiotic effectiveness. It shouldn't start immediately,
and shouldn't wear off immediately.

So let's skip all that and try this again.

### Model 1.5.0

```{r eval=T, fig.width=10, fig.height=10}
d1.5.0.sp <- d2 %>% filter(specimen_type == "Sputum") %>%
  select(subject_id=subject_id2, specimen_id2, study_day, total_reads, read_count, abx_yn, on_abx) %>%
  # Remove empty or single-sample subjects
  group_by(subject_id) %>%
  filter(n() > 1) %>%
  arrange(subject_id, study_day) %>%
  # Add lagged read and empirical proportion terms
  mutate(lag_count = lag(read_count)) %>%
  mutate(lag_emp_prop = lag(read_count)/lag(total_reads)) %>%
  # Remove missing cases 
  filter(!is.na(lag_count) & !is.na(read_count)) %>%
  ungroup() %>%
  droplevels()

ggplot(d1.5.0.sp, aes(x=study_day, y=read_count/total_reads, color=on_abx, group=subject_id)) +
  geom_point(shape=21) +
  geom_line() +
  geom_vline(aes(xintercept=study_day, alpha=abx_yn)) +
  scale_alpha_manual(values=c("TRUE"=0.6, "FALSE"=0), na.value=0) +
  scale_y_continuous(labels=scales::percent) +
  facet_wrap(~ subject_id, scales="free", ncol=3)

d1.5.0.spl <- compose_data(d1.5.0.sp)
```

```{r, eval=T, results='asis'}
if (params$load_saved) {
  m1.5.0.sp <- readRDS("fit_arb_1.5.0_sputum.rds")
} else {
  m1.5.0.sp <- stan(
    file="arb_1.5.0.stan", data=d1.5.0.spl, iter=2000, chains=4,
    control=list(max_treedepth=15, adapt_delta=0.9))
  saveRDS(m1.5.0.sp, file="fit_arb_1.5.0_sputum.rds")
}
p1.5.0.sp <- recover_types(m1.5.0.sp, d1.5.0.sp) %>%
  spread_samples(mu, a_subj[subject_id], b_lag, b_abx[subject_id])
median_qi(p1.5.0.sp) %>%
  kable() %>%
  kable_styling(bootstrap_options=c("striped", "hover", "condensed", "responsive"))

```

```{r}
m1.5.0a.sp <- stan(
  file="arb_1.5.0a.stan", data=d1.5.0.spl, iter=2000, chains=4,
  control=list(max_treedepth=15, adapt_delta=0.9))
saveRDS(m1.5.0a.sp, file="fit_arb_1.5.0a_sputum.rds")
bayesplot::mcmc_trace(rstan::extract(m1.5.0a.sp, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag"))
pairs(m1.5.0.sp, pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag", "b_abx[1]"))
```


```{r}
bayesplot::mcmc_trace(rstan::extract(m1.5.0.sp, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag"))
pairs(m1.5.0a.sp, pars=c("mu", "sigma_spec", "sigma_subj", "sigma_abx", "a_spec[1]", "b_lag", "b_abx[1]"))
```

#### Post. predictive

```{r}
invisible(with(data.frame(), {
  # browser()
  .m <- m1.5.0a.sp
  .d <- d1.5.0.sp
  .m <- recover_types(.m, .d)
  post <- spread_samples(.m, mu, sigma_spec, sigma_subj, sigma_abx, b_lag, a_spec[specimen_id2], a_subj[subject_id], b_abx[subject_id])
  post$specimen_idx <- as.integer(post$specimen_id2)
  post2 <- left_join(post, .d) %>% filter(!is.na(read_count))
  
  pp_subject <- function(post, subject, use_a_spec=F) {
    ps <- post %>% filter(subject_id == subject)
    stopifnot(nrow(ps) > 0)
    ps$specimen_idx <- as.integer(as.factor(ps$specimen_id2))
    cols <- n_distinct(ps$specimen_id2)
    rows <- nrow(ps)/cols
    pred_prob <- matrix(data=NA, nrow=rows, ncol=cols) 
    
    
    p.link <- function(d, n, idx, prev_prop) {
      d2 <- filter(d, specimen_idx == idx)
      prob <- logistic(with(d2, mu + a_subj + a_spec*use_a_spec + b_lag * prev_prop + b_abx * on_abx))
      rbinom(n, unique(d2$total_reads), prob)/unique(d2$total_reads)
    }
    
    pred_prob[,1] <- p.link(ps, rows, 1, .d$lag_emp_prop[1])
    
    # Skip autoregression if only one timepoint
    if (cols > 1) {
      for (i in 2:cols) {
        pred_prob[,i] <- p.link(ps, rows, i, pred_prob[,i-1])
      }
    }
    
    pred.df <- gather(data.frame(pred_prob)) %>%
      mutate(key = as.factor(key))
    levels(pred.df$key) <- levels(as.factor(ps$specimen_id2))
    
    pred.df.sub <- group_by(pred.df, key) %>%
      mutate(group = seq_along(value)) %>%
      filter(group < 150) %>%
      rename(specimen_id2=key, pred_prob=value) %>%
      left_join(.d) %>%
      mutate(emp_prob = read_count/total_reads)
    
    dp = pred.df.sub %>% ungroup %>% distinct(specimen_id2, .keep_all = T)
    
    ggplot(pred.df.sub, aes(study_day, pred_prob, group=group)) +
      geom_line(alpha=0.1) +
      geom_line(data=dp, aes(y=emp_prob, group=NULL), color="red") +
      geom_vline(data=dp, aes(xintercept=study_day, alpha=on_abx), linetype=2) +
      scale_alpha_manual(values=c("TRUE"=0.6, "FALSE"=0), guide=FALSE) +
      scale_y_continuous(expand=c(0,0), labels=scales::percent) +
      ggtitle(subject)
  }
  
  pp_subject_plots <- lapply(X = as.character(unique(post$subject_id)), function(s) {
    print(s)
    pp_subject(post2, s, T)
  })
  all_plots <- Reduce(`+`, pp_subject_plots)
  plot(all_plots)
}))
```

### Model 1.5.1

Previously the lag proportions and the abx effect were additive. This next model
has them interacting.

```{r}
m1.5.1.sp <- stan(
  file="arb_1.5.1.stan", data=d1.5.0.spl, iter=2000, chains=4,
  control=list(max_treedepth=15, adapt_delta=0.9))
saveRDS(m1.5.1.sp, file="fit_arb_1.5.1_sputum.rds")
p1.5.1.sp <- recover_types(m1.5.1.sp, d1.5.0.sp) %>%
  spread_samples(mu, a_subj[subject_id], b_lag, b_abx[subject_id])
median_qi(p1.5.1.sp)
bayesplot::mcmc_trace(rstan::extract(m1.5.1.sp, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag"))
pairs(m1.5.1.sp, pars=c("mu", "sigma_spec", "sigma_subj", "a_spec[1]", "b_lag", "b_abx[1]"))
```

### Model 1.5.2

Jason suggested coding the previous day's terms as a presence/absence variable
for the interaction with antibiotics. This would make it simpler to understand
the resulting coefficient as well.

```{r}
d1.5.2.sp <- d1.5.0.sp %>%
  mutate(lag_nonzero = lag_count > 0)

d1.5.2.spl <- compose_data(d1.5.2.sp)

m1.5.2.sp <- stan(
  file="arb_1.5.2.stan", data=d1.5.2.spl, iter=2000, chains=4,
  control=list(max_treedepth=15, adapt_delta=0.9))
saveRDS(m1.5.2.sp, file="fit_arb_1.5.2_sputum.rds")

s1.5.2.sp <- summary(m1.5.2.sp)$summary %>% 
  as.data.frame() %>% 
  rownames_to_column("parameter") %>% 
  as.tibble()

p1.5.2.sp <- recover_types(m1.5.2.sp, d1.5.0.sp) %>%
  spread_samples(mu, a_subj[subject_id], b_lag, b_abx[subject_id])
median_qi(p1.5.2.sp)
bayesplot::mcmc_trace(rstan::extract(m1.5.2.sp, inc_warmup=F, permuted=F), pars=c("mu", "sigma_spec", "sigma_subj", "sigma_abx", "a_spec[1]", "b_lag"))
pairs(m1.5.2.sp, pars=c("mu", "sigma_spec", "sigma_subj", "sigma_abx", "a_spec[1]", "b_lag", "b_abx[1]"))
```


```{r}

```

